# Import necessary libraries
import pandas as pd
import numpy as np
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Step 1: Load the cleaned dataset
file_path = 'cleaned_drug_demand_data.csv'  # Update with your actual file path
df_cleaned = pd.read_csv(file_path)

# Ensure the data has a proper time column
df_cleaned['Date'] = pd.date_range(start='2020-01-01', periods=len(df_cleaned), freq='D')
df_cleaned.set_index('Date', inplace=True)

# Splitting data for time series and feature-based models
df_time_series = df_cleaned[['Demand']].copy()
X = df_cleaned.drop(columns=['Demand'])
y = df_cleaned['Demand']

# Step 2: Feature Engineering (for feature-based models)
# Adding time-based features
X['Day'] = X.index.day
X['Month'] = X.index.month
X['Year'] = X.index.year
X['WeekOfYear'] = X.index.isocalendar().week
X['DayOfWeek'] = X.index.dayofweek

# Train-test split for feature-based models (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)

# Step 3: Model 1 - Exponential Smoothing (Time-Series Model)
model_ts = ExponentialSmoothing(
    df_time_series['Demand'], 
    trend='add', 
    seasonal='add', 
    seasonal_periods=365  # Assuming yearly seasonality
)
model_ts_fit = model_ts.fit()
forecast_ts = model_ts_fit.forecast(30)  # Forecast next 30 days

# Step 4: Model 2 - Random Forest (Feature-Based Model)
model_rf = RandomForestRegressor(n_estimators=100, random_state=42)
model_rf.fit(X_train, y_train)
forecast_rf = model_rf.predict(X_test)

# Step 5: Evaluation Metrics
# Time-Series Model Metrics
metrics_ts = {
    'RMSE': np.sqrt(mean_squared_error(y[-30:], forecast_ts)),
    'MAE': mean_absolute_error(y[-30:], forecast_ts),
    'R^2': r2_score(y[-30:], forecast_ts)
}

# Random Forest Model Metrics
metrics_rf = {
    'RMSE': np.sqrt(mean_squared_error(y_test, forecast_rf)),
    'MAE': mean_absolute_error(y_test, forecast_rf),
    'R^2': r2_score(y_test, forecast_rf)
}

# Step 6: Feature Importance (Random Forest)
feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': model_rf.feature_importances_
}).sort_values(by='Importance', ascending=False)

# Step 7: Plotting Results
# Plot Exponential Smoothing Forecast
plt.figure(figsize=(12, 6))
plt.plot(df_time_series['Demand'], label='Actual Demand', color='blue')
plt.plot(forecast_ts, label='Forecast (Exponential Smoothing)', linestyle='--', color='orange')
plt.title('Drug Demand Forecasting (Exponential Smoothing)')
plt.xlabel('Date')
plt.ylabel('Demand')
plt.legend()
plt.show()

# Plot Feature Importance (Random Forest)
plt.figure(figsize=(10, 6))
plt.barh(feature_importances['Feature'][:10], feature_importances['Importance'][:10])
plt.title('Top 10 Feature Importances (Random Forest)')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.gca().invert_yaxis()
plt.show()

# Step 8: Compare Models
metrics_summary = pd.DataFrame({
    'Model': ['Exponential Smoothing', 'Random Forest'],
    'RMSE': [metrics_ts['RMSE'], metrics_rf['RMSE']],
    'MAE': [metrics_ts['MAE'], metrics_rf['MAE']],
    'R^2': [metrics_ts['R^2'], metrics_rf['R^2']]
})

# Display Results
print("Model Comparison Metrics:")
print(metrics_summary)

print("\nFeature Importance (Random Forest):")
print(feature_importances.head(10))

# Step 9: Save Models for Deployment
import joblib
joblib.dump(model_ts_fit, 'exponential_smoothing_model.pkl')
joblib.dump(model_rf, 'random_forest_model.pkl')

print("\nModels saved: 'exponential_smoothing_model.pkl' and 'random_forest_model.pkl'")


