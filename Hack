updated------------

# Import necessary libraries
import pandas as pd
import numpy as np
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Step 1: Load the cleaned dataset
file_path = 'cleaned_drug_demand_data.csv'  # Update with your actual file path
df_cleaned = pd.read_csv(file_path)

# Ensure the data has a proper time column
df_cleaned['Date'] = pd.date_range(start='2020-01-01', periods=len(df_cleaned), freq='D')
df_cleaned.set_index('Date', inplace=True)

# Splitting data for time series and feature-based models
df_time_series = df_cleaned[['Demand']].copy()
X = df_cleaned.drop(columns=['Demand'])
y = df_cleaned['Demand']

# Step 2: Feature Engineering (for feature-based models)
# Adding time-based features
X['Day'] = X.index.day
X['Month'] = X.index.month
X['Year'] = X.index.year
X['WeekOfYear'] = X.index.isocalendar().week
X['DayOfWeek'] = X.index.dayofweek

# Train-test split for feature-based models (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)

# Step 3: Model 1 - Exponential Smoothing (Time-Series Model)
model_ts = ExponentialSmoothing(
    df_time_series['Demand'], 
    trend='add', 
    seasonal='add', 
    seasonal_periods=365  # Assuming yearly seasonality
)
model_ts_fit = model_ts.fit()
forecast_ts = model_ts_fit.forecast(30)  # Forecast next 30 days

# Step 4: Model 2 - Random Forest (Feature-Based Model)
model_rf = RandomForestRegressor(n_estimators=100, random_state=42)
model_rf.fit(X_train, y_train)
forecast_rf = model_rf.predict(X_test)

# Step 5: Inventory Optimization
# Define lead time (e.g., 5 days) and service level (e.g., 95%)
lead_time = 5
z_score = 1.96  # For 95% service level

# Calculate average daily demand and standard deviation
avg_daily_demand = y_train.mean()
std_dev_demand = y_train.std()

# Calculate Safety Stock and Reorder Point (ROP)
safety_stock = z_score * (std_dev_demand * np.sqrt(lead_time))
reorder_point = (avg_daily_demand * lead_time) + safety_stock

print(f"Inventory Optimization Metrics:")
print(f"Average Daily Demand: {avg_daily_demand:.2f}")
print(f"Standard Deviation of Demand: {std_dev_demand:.2f}")
print(f"Safety Stock: {safety_stock:.2f}")
print(f"Reorder Point (ROP): {reorder_point:.2f}")

# Step 6: Evaluation Metrics
# Time-Series Model Metrics
metrics_ts = {
    'RMSE': np.sqrt(mean_squared_error(y[-30:], forecast_ts)),
    'MAE': mean_absolute_error(y[-30:], forecast_ts),
    'R^2': r2_score(y[-30:], forecast_ts)
}

# Random Forest Model Metrics
metrics_rf = {
    'RMSE': np.sqrt(mean_squared_error(y_test, forecast_rf)),
    'MAE': mean_absolute_error(y_test, forecast_rf),
    'R^2': r2_score(y_test, forecast_rf)
}

# Step 7: Feature Importance (Random Forest)
feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': model_rf.feature_importances_
}).sort_values(by='Importance', ascending=False)

# Step 8: Compare Models
metrics_summary = pd.DataFrame({
    'Model': ['Exponential Smoothing', 'Random Forest'],
    'RMSE': [metrics_ts['RMSE'], metrics_rf['RMSE']],
    'MAE': [metrics_ts['MAE'], metrics_rf['MAE']],
    'R^2': [metrics_ts['R^2'], metrics_rf['R^2']]
})

# Display Results
print("\nModel Comparison Metrics:")
print(metrics_summary)

print("\nFeature Importance (Random Forest):")
print(feature_importances.head(10))

# Save Models for Deployment
import joblib
joblib.dump(model_ts_fit, 'exponential_smoothing_model.pkl')
joblib.dump(model_rf, 'random_forest_model.pkl')

print("\nModels saved: 'exponential_smoothing_model.pkl' and 'random_forest_model.pkl'")
