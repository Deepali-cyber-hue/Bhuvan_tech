import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_excel('drug_demand_forecasting.xlsx', sheet_name='Sheet1')

# Step 1: Replace '.' with NaN
df = df.replace({'.': np.nan})

# Step 2: Convert numeric columns to float
numeric_columns = ['Demand', 'Weekday', 'Prescription_Volume']
for col in numeric_columns:
    df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric, handling invalid values

# Step 3: Handle Missing Values for Numeric Columns
# Fill missing numeric values with median
for col in numeric_columns:
    df[col].fillna(df[col].median(), inplace=True)

# Step 4: Handle Missing Values for Categorical Columns
categorical_columns = ['Season', 'Month', 'Drug_Type']
for col in categorical_columns:
    df[col].fillna(df[col].mode()[0], inplace=True)

# Step 5: Process the 'Age' Column
# Convert age ranges to numeric midpoints
def process_age(value):
    if isinstance(value, str) and '-' in value:  # Handle ranges like '26-35'
        start, end = map(int, value.split('-'))
        return (start + end) / 2
    elif value == '60+':  # Handle '60+'
        return 65  # Assume 65 as a midpoint
    else:
        return value  # Leave numeric values as-is

df['Age'] = df['Age'].apply(process_age)

# Step 6: Encode Categorical Variables
# One-hot encode categorical features
df_encoded = pd.get_dummies(df, columns=['Region', 'Category', 'Drug_Type', 'Season', 'Month', 'age_group'], drop_first=True)

# Step 7: Drop Irrelevant Columns
# Remove columns that won't contribute to numerical modeling
df_encoded = df_encoded.drop(columns=['Date', 'Drug', 'Sides', 'Event', 'Market_News', 'Press_Release'])

# Step 8: Save Cleaned Data
df_encoded.to_csv('cleaned_drug_demand_data.csv', index=False)

print("Data cleaning complete. Cleaned data saved as 'cleaned_drug_demand_data.csv'.")




write promt do time series modelling for this
Prediction and Forecast:
• Select and justify appropriate algorithms for prediction.
• Implement feature engineering techniques to improve model performance.
• Solution should take account Seasonality, Trends and Stationary effect for forecast.
• Develop at least two different models.
• Evaluate and compare model performance using relevant metrics.
• Identify the most important features contributing model....................or yai tho kiya hai abhi 
CODE -
# Import necessary libraries
import pandas as pd
import numpy as np
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Load the cleaned dataset
file_path = 'cleaned_drug_demand_data.csv'  # Update with your actual file path
df_cleaned = pd.read_csv(file_path)

# Ensure the data has a proper time index
df_cleaned['Date'] = pd.date_range(start='2020-01-01', periods=len(df_cleaned), freq='D')
df_cleaned.set_index('Date', inplace=True)

# Step 1: Prepare the data
df_time_series = df_cleaned[['Demand']].copy()

# Split the data into training and test sets (80-20 split)
train_size = int(len(df_time_series) * 0.8)
train, test = df_time_series[:train_size], df_time_series[train_size:]

# Step 2: Model 1 - ARIMA
# Fitting the ARIMA model (order can be fine-tuned)
model_arima = ARIMA(train['Demand'], order=(1, 1, 1))
model_arima_fit = model_arima.fit()

# Forecasting with ARIMA
forecast_arima = model_arima_fit.forecast(steps=len(test))

# Step 3: Model 2 - Exponential Smoothing
# Fitting the Exponential Smoothing model
model_exp = ExponentialSmoothing(
    train['Demand'], trend='add', seasonal='add', seasonal_periods=365
)
model_exp_fit = model_exp.fit()

# Forecasting with Exponential Smoothing
forecast_exp = model_exp_fit.forecast(steps=len(test))

# Step 4: Evaluation Metrics
# ARIMA Metrics
metrics_arima = {
    'RMSE': np.sqrt(mean_squared_error(test['Demand'], forecast_arima)),
    'MAE': mean_absolute_error(test['Demand'], forecast_arima),
    'R^2': r2_score(test['Demand'], forecast_arima)
}

# Exponential Smoothing Metrics
metrics_exp = {
    'RMSE': np.sqrt(mean_squared_error(test['Demand'], forecast_exp)),
    'MAE': mean_absolute_error(test['Demand'], forecast_exp),
    'R^2': r2_score(test['Demand'], forecast_exp)
}

# Step 5: Visualizing the Forecast
plt.figure(figsize=(12, 6))
plt.plot(train['Demand'], label='Training Data', color='blue')
plt.plot(test['Demand'], label='Test Data', color='green')
plt.plot(test.index, forecast_arima, label='ARIMA Forecast', linestyle='--', color='orange')
plt.plot(test.index, forecast_exp, label='Exponential Smoothing Forecast', linestyle='--', color='red')
plt.title('Drug Demand Forecasting')
plt.xlabel('Date')
plt.ylabel('Demand')
plt.legend()
plt.show()

# Step 6: Displaying Metrics
metrics_summary = pd.DataFrame({
    'Model': ['ARIMA', 'Exponential Smoothing'],
    'RMSE': [metrics_arima['RMSE'], metrics_exp['RMSE']],
    'MAE': [metrics_arima['MAE'], metrics_exp['MAE']],
    'R^2': [metrics_arima['R^2'], metrics_exp['R^2']]
})

print("Model Comparison Metrics:")
print(metrics_summary)

# Save the models for deployment
import joblib
joblib.dump(model_arima_fit, 'arima_model.pkl')
joblib.dump(model_exp_fit, 'exponential_smoothing_model.pkl')

print("\nModels saved: 'arima_model.pkl' and 'exponential_smoothing_model.pkl'")

COMMENTS - 
Models Implemented:
ARIMA:

Accounts for trends, seasonality, and stationarity.
Suitable for univariate time-series forecasting.
Exponential Smoothing:

Captures additive trends and seasonal effects.
Assumes consistent seasonal patterns over time.
Evaluation Metrics:
Model	RMSE	MAE	 R^2

 
ARIMA	42,594	42,594	-1,160,119
Exponential Smoothing	1,028,587	87,793	-676,517,442

RMSE (Root Mean Squared Error): Measures the standard deviation of prediction errors.
MAE (Mean Absolute Error): Captures the average magnitude of errors.

R^2 : Indicates how well the model explains variability in demand (negative values show poor fit).

Insights:
Performance:

Both models struggle with the dataset, likely due to high variability or noise in demand.
ARIMA outperforms Exponential Smoothing in terms of lower RMSE and MAE.
Challenges:

Data may have inconsistencies, outliers, or unexplained variability.
Additional preprocessing or advanced modeling (e.g., machine learning models) could help.
